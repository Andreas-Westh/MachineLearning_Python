{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple perceptron\n",
    "https://www.youtube.com/watch?v=-KLnurhX-Pg&list=PLqXS1b2lRpYTpUIEu3oxfhhTuBXmMPppA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general values\n",
    "X_input = [0.1,0.5,0.2]\n",
    "w_weights = [0.4, 0.3, 0.6]\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define activation function\n",
    "def step(weighted_sum):\n",
    "    if weighted_sum > threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04000000000000001\n",
      "0.19\n",
      "0.31\n",
      "output: 0\n"
     ]
    }
   ],
   "source": [
    "# now we can define our perceptron\n",
    "def perceptron():\n",
    "    weighted_sum = 0\n",
    "    for x,w in zip(X_input, w_weights):\n",
    "        weighted_sum += x*w\n",
    "        print(weighted_sum)\n",
    "    return step(weighted_sum)\n",
    "\n",
    "output = perceptron()\n",
    "print(\"output: \" + str(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Entropy Loss Error Function\n",
    "https://www.youtube.com/watch?v=EJRFP3WmS6Q&list=PLqXS1b2lRpYTpUIEu3oxfhhTuBXmMPppA\n",
    "\n",
    "\n",
    "We need to make a distriction in our code, for the output we **want**, since that is not always the output we **get** \n",
    "Desired outpus (Target/y) vs actual output (predection/y^)\n",
    "\n",
    "We can **NEVER** mopdify the actual output, as that is fact, but we can modify our prediction, till it is (or gets close to) being the perfect match with the actual output\n",
    "\n",
    "For this we need to use the Error Function, aka Loss Function, real ones know em as Cost tho on god\n",
    "    It calculated the distance between a given point and the target\n",
    "\n",
    "This part will focus on Cross Entrophy Loss aka Log Loss:\n",
    "$$\n",
    "-\\left( y \\times \\log(\\text{w\\_sum}) + (1 - y) \\times \\log(1 - \\text{w\\_sum}) \\right)\n",
    "$$\n",
    "\n",
    "\n",
    "Incorrectly classified inputs, get a bigger penalty than inputs that were correctly classified\n",
    "\n",
    "Now to calculate the total loss:\n",
    "$$\n",
    "\\frac{\\text{loss}[1] + \\text{loss}[2] + \\text{loss}[\\dots] + \\text{loss}[n]}{n}\n",
    "$$\n",
    "*n being the number of observations*\n",
    "\n",
    "and these 2 funtions combined is:\n",
    "$$\n",
    "\\frac{\\sum\\limits_{i=0}^{n} - \\left( y_i \\times \\log(\\text{w\\_sum}_i) + (1 - y_i) \\times \\log(1 - \\text{w\\_sum}_i) \\right)}{n}\n",
    "$$\n",
    "*i = each of our observations, one at a time, a bit like an i in a for loop* \n",
    "\n",
    "Now to coding this bad boy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
